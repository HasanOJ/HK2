# Ollama Configuration (Local LLM)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:3b

# Alternative models (uncomment to use):
# OLLAMA_MODEL=llama3.2:3b
# OLLAMA_MODEL=phi3:mini
